{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from model import Hash2ImageModel\n",
    "from data import Hash2ImgDataset\n",
    "from hash import compute_hash, hash2tensor\n",
    "\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import lpips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "DEVICE = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "# Using color images or not\n",
    "rgb = True\n",
    "\n",
    "# Create the dataset and data loader for training\n",
    "if rgb:\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "else:\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5), (0.5))\n",
    "    ])\n",
    "\n",
    "dataset = Hash2ImgDataset(image_paths='./celeba_data_photodna/val/images', hash_paths='./celeba_data_photodna/val/hashes.pkl', hash_func='photodna', transforms=transform)\n",
    "loader = DataLoader(dataset, batch_size=BATCH_SIZE)\n",
    "# Load the photodna model \n",
    "model_path = '/Users/neddamj/Documents/BU/Research/2022PhotoDNA/nnhash/inversion/saved_models/2024-03-21_15:13:35%_photodna_celeba_saved_model.pth'\n",
    "model = Hash2ImageModel(rgb=rgb, hash_func='photodna')\n",
    "checkpoint = torch.load(model_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.to(DEVICE)\n",
    "model = model.eval()\n",
    "\n",
    "# Load the pdq model \n",
    "model_path = '/Users/neddamj/Documents/BU/Research/2022PhotoDNA/nnhash/inversion/saved_models/pdq_2024-04-03_11:15:35%_celeba_saved_model.pth'\n",
    "pdq_model = Hash2ImageModel(rgb=rgb, hash_func='pdq')\n",
    "checkpoint = torch.load(model_path)\n",
    "pdq_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "pdq_model.to(DEVICE)\n",
    "pdq_model = pdq_model.eval()\n",
    "\n",
    "# Load the neuralhash model \n",
    "model_path = '/Users/neddamj/Documents/BU/Research/2022PhotoDNA/nnhash/inversion/saved_models/2024-03-16_09:35:15%_celeba_saved_model.pth'\n",
    "nn_model = Hash2ImageModel(rgb=rgb, hash_func='neuralhash')\n",
    "checkpoint = torch.load(model_path)\n",
    "nn_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "nn_model.to(DEVICE)\n",
    "nn_model = nn_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invert_photodna(num):\n",
    "    for i, (hash, image) in enumerate(loader):\n",
    "        hash, image = hash.to(DEVICE), image.to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            pred_img = model(hash)   \n",
    "        pred_img = pred_img.to(torch.device('cpu'))\n",
    "        pred_img = pred_img.squeeze(0).detach().permute(1, 2, 0)\n",
    "        image = image.to(torch.device('cpu'))\n",
    "        image = image.squeeze(0).detach().permute(1, 2, 0)\n",
    "        if i == num-1:\n",
    "            break\n",
    "    return image, pred_img\n",
    "\n",
    "def invert_pdq(num):\n",
    "    pdq_hash = compute_hash(f'/Users/neddamj/Documents/BU/Research/2022PhotoDNA/nnhash/inversion/celeba_data_photodna/val/images/{num}.jpeg', hash_func='pdq')\n",
    "    with torch.no_grad():\n",
    "        tensor = hash2tensor(pdq_hash.copy(), hash_func='pdq').unsqueeze(0)\n",
    "        pred_img = pdq_model(tensor.to(DEVICE))\n",
    "    pred_img = pred_img.to(torch.device('cpu'))\n",
    "    pred_img = pred_img.squeeze(0).detach().permute(1, 2, 0)\n",
    "    return pred_img\n",
    "\n",
    "def invert_neuralhash(num):\n",
    "    nn_hash = compute_hash(f'/Users/neddamj/Documents/BU/Research/2022PhotoDNA/nnhash/inversion/celeba_data_photodna/val/images/{num}.jpeg', hash_func='neuralhash')\n",
    "    with torch.no_grad():\n",
    "        pred_img = nn_model(hash2tensor(nn_hash, hash_func='neuralhash').unsqueeze(0).to(DEVICE))\n",
    "    pred_img = pred_img.to(torch.device('cpu'))\n",
    "    pred_img = pred_img.squeeze(0).detach().permute(1, 2, 0)\n",
    "    return pred_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_inversions(image, photo_img, pdq_img, nn_img):\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title('Ground Truth')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.imshow(photo_img)\n",
    "    plt.title('PhotoDNA')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.imshow(pdq_img)\n",
    "    plt.title('PDQ')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.imshow(nn_img)\n",
    "    plt.title('NeuralHash')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 27 and 32\n",
    "image_num = 32\n",
    "image, photo_img = invert_photodna(image_num)\n",
    "pdq_img = invert_pdq(image_num)\n",
    "nn_img = invert_neuralhash(image_num)\n",
    "plot_inversions(image, photo_img, pdq_img, nn_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptual_sim = lpips.LPIPS(net='vgg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('PhotoDNA')\n",
    "l2_dist = np.linalg.norm(image - photo_img)/np.sqrt(64*64*3)\n",
    "print(f'L2 Distance: {l2_dist}')\n",
    "# Find the SSIM between the original and geneerated images\n",
    "ssim_score = ssim(np.array(image), np.array(photo_img), channel_axis=-1, data_range=1)\n",
    "print(f'SSIM Score: {ssim_score}')\n",
    "# Calculate the perceptual similarity\n",
    "image, photo_img = image.permute(2, 0, 1), photo_img.permute(2, 0, 1)\n",
    "d = perceptual_sim(image, photo_img, normalize=True)\n",
    "print(f'LPIPS Score: {d.detach().numpy()}')\n",
    "image, photo_img = image.permute(1, 2, 0), photo_img.permute(1, 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('PDQ')\n",
    "l2_dist = np.linalg.norm(image - pdq_img)/np.sqrt(64*64*3)\n",
    "print(f'L2 Distance: {l2_dist}')\n",
    "# Find the SSIM between the original and geneerated images\n",
    "ssim_score = ssim(np.array(image), np.array(pdq_img), channel_axis=-1, data_range=1)\n",
    "print(f'SSIM Score: {ssim_score}')\n",
    "# Calculate the perceptual similarity\n",
    "image, pdq_img = image.permute(2, 0, 1), pdq_img.permute(2, 0, 1)\n",
    "d = perceptual_sim(image, pdq_img, normalize=True)\n",
    "print(f'LPIPS Score: {d.detach().numpy()}')\n",
    "image, pdq_img = image.permute(1, 2, 0), pdq_img.permute(1, 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('NeuralHash')\n",
    "l2_dist = np.linalg.norm(image - nn_img)/np.sqrt(64*64*3)\n",
    "print(f'L2 Distance: {l2_dist}')\n",
    "# Find the SSIM between the original and geneerated images\n",
    "ssim_score = ssim(np.array(image), np.array(nn_img), channel_axis=-1, data_range=1)\n",
    "print(f'SSIM Score: {ssim_score}')\n",
    "# Calculate the perceptual similarity\n",
    "image, nn_img = image.permute(2, 0, 1), nn_img.permute(2, 0, 1)\n",
    "d = perceptual_sim(image, nn_img, normalize=True)\n",
    "print(f'LPIPS Score: {d.detach().numpy()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nhash",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
